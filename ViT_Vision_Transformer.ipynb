{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DNIGmpVGpHaO"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#variables\n",
        "batch_size = 64\n",
        "img_size = 28\n",
        "patch_size = 7\n",
        "num_channels = 1\n",
        "num_patches = (img_size // patch_size) ** 2\n",
        "num_heads = 1\n",
        "embed_dim = 16\n",
        "mlp_dim = 16\n",
        "transformer_units = 1"
      ],
      "metadata": {
        "id": "YqJ5HW9wrIXu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "h8BWHuDFrKhI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "valset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                        download=True, transform=transform)"
      ],
      "metadata": {
        "id": "_WpWrB_ArLKa"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create train and val batches\n",
        "train_data = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "val_data = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "5SFBdO1-rO2p"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.proj=nn.Conv2d(in_channels=num_channels,out_channels=embed_dim,kernel_size=patch_size,stride=patch_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.proj(x)\n",
        "    x=x.flatten(2)\n",
        "    x=x.transpose(1,2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FIDYOo8dtBcz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ln1=nn.LayerNorm(embed_dim)\n",
        "    self.attn=nn.MultiheadAttention(embed_dim,num_heads,batch_first=True)\n",
        "    self.ln2=nn.LayerNorm(embed_dim)\n",
        "    self.mlp=nn.Sequential(\n",
        "        nn.Linear(embed_dim,mlp_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(mlp_dim,embed_dim)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=x+self.attn(self.ln1(x),self.ln1(x),self.ln1(x))[0]\n",
        "    x=x+self.mlp(self.ln2(x))\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "nNEmHowyxIey"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.patch_embed=PatchEmbedding()\n",
        "    self.cls_token=nn.Parameter(torch.randn(1,1,embed_dim))\n",
        "    self.pos_embed=nn.Parameter(torch.randn(1,num_patches+1,embed_dim))\n",
        "    self.blocks=nn.ModuleList([Block() for _ in range(transformer_units)])\n",
        "    self.mlp_head=nn.Sequential(nn.LayerNorm(embed_dim),nn.Linear(embed_dim,10))\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.patch_embed(x)\n",
        "    B=x.size(0)\n",
        "    cls_token=self.cls_token.expand((B,-1,-1))\n",
        "    x=torch.cat((cls_token,x),dim=1)\n",
        "    x=x+self.pos_embed\n",
        "    for block in self.blocks:\n",
        "      x=block(x)\n",
        "    x=x[:,0]\n",
        "    x=self.mlp_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "CG-az5sOxMd0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ViT().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "pcAH2p0I5LTM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_epoch = 0\n",
        "    total_epoch = 0\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_data):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss+=loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        correct = (preds == labels).sum().item()\n",
        "        accuracy = 100.0 * correct / labels.size(0)\n",
        "\n",
        "        correct_epoch += correct\n",
        "        total_epoch += labels.size(0)\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"  Batch {batch_idx+1:3d}: Loss = {loss.item():.4f}, Accuracy = {accuracy:.2f}%\")\n",
        "\n",
        "    epoch_acc = 100.0 * correct_epoch / total_epoch\n",
        "    print(f\"==> Epoch {epoch+1} Summary: Total Loss = {total_loss:.4f}, Accuracy = {epoch_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AezDj0ZX5dax",
        "outputId": "a04f614c-09c0-4239-be2b-8124684eb866"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "  Batch   1: Loss = 2.5558, Accuracy = 4.69%\n",
            "  Batch 101: Loss = 1.0887, Accuracy = 62.50%\n",
            "  Batch 201: Loss = 0.9266, Accuracy = 68.75%\n",
            "  Batch 301: Loss = 0.7843, Accuracy = 68.75%\n",
            "  Batch 401: Loss = 0.5988, Accuracy = 78.12%\n",
            "  Batch 501: Loss = 0.6998, Accuracy = 78.12%\n",
            "  Batch 601: Loss = 0.6530, Accuracy = 70.31%\n",
            "  Batch 701: Loss = 0.6283, Accuracy = 79.69%\n",
            "  Batch 801: Loss = 0.6526, Accuracy = 75.00%\n",
            "  Batch 901: Loss = 0.4347, Accuracy = 84.38%\n",
            "==> Epoch 1 Summary: Total Loss = 795.1363, Accuracy = 70.54%\n",
            "\n",
            "Epoch 2\n",
            "  Batch   1: Loss = 0.5333, Accuracy = 81.25%\n",
            "  Batch 101: Loss = 0.4872, Accuracy = 84.38%\n",
            "  Batch 201: Loss = 0.6539, Accuracy = 76.56%\n",
            "  Batch 301: Loss = 0.6245, Accuracy = 78.12%\n",
            "  Batch 401: Loss = 0.7325, Accuracy = 76.56%\n",
            "  Batch 501: Loss = 0.5388, Accuracy = 76.56%\n",
            "  Batch 601: Loss = 0.5595, Accuracy = 79.69%\n",
            "  Batch 701: Loss = 0.3659, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.6799, Accuracy = 76.56%\n",
            "  Batch 901: Loss = 0.4001, Accuracy = 87.50%\n",
            "==> Epoch 2 Summary: Total Loss = 502.3556, Accuracy = 82.81%\n",
            "\n",
            "Epoch 3\n",
            "  Batch   1: Loss = 0.4290, Accuracy = 84.38%\n",
            "  Batch 101: Loss = 0.5004, Accuracy = 81.25%\n",
            "  Batch 201: Loss = 0.3372, Accuracy = 85.94%\n",
            "  Batch 301: Loss = 0.7399, Accuracy = 78.12%\n",
            "  Batch 401: Loss = 0.4679, Accuracy = 82.81%\n",
            "  Batch 501: Loss = 0.3332, Accuracy = 89.06%\n",
            "  Batch 601: Loss = 0.4070, Accuracy = 89.06%\n",
            "  Batch 701: Loss = 0.4261, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.3078, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.2642, Accuracy = 93.75%\n",
            "==> Epoch 3 Summary: Total Loss = 411.1750, Accuracy = 86.20%\n",
            "\n",
            "Epoch 4\n",
            "  Batch   1: Loss = 0.3319, Accuracy = 85.94%\n",
            "  Batch 101: Loss = 0.1820, Accuracy = 96.88%\n",
            "  Batch 201: Loss = 0.2793, Accuracy = 92.19%\n",
            "  Batch 301: Loss = 0.5531, Accuracy = 81.25%\n",
            "  Batch 401: Loss = 0.3691, Accuracy = 87.50%\n",
            "  Batch 501: Loss = 0.2115, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.6417, Accuracy = 82.81%\n",
            "  Batch 701: Loss = 0.1813, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.3294, Accuracy = 92.19%\n",
            "  Batch 901: Loss = 0.5082, Accuracy = 79.69%\n",
            "==> Epoch 4 Summary: Total Loss = 361.5114, Accuracy = 88.00%\n",
            "\n",
            "Epoch 5\n",
            "  Batch   1: Loss = 0.1789, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.4124, Accuracy = 84.38%\n",
            "  Batch 201: Loss = 0.3633, Accuracy = 89.06%\n",
            "  Batch 301: Loss = 0.3010, Accuracy = 90.62%\n",
            "  Batch 401: Loss = 0.6744, Accuracy = 81.25%\n",
            "  Batch 501: Loss = 0.3015, Accuracy = 87.50%\n",
            "  Batch 601: Loss = 0.2915, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.5256, Accuracy = 82.81%\n",
            "  Batch 801: Loss = 0.7675, Accuracy = 76.56%\n",
            "  Batch 901: Loss = 0.3109, Accuracy = 90.62%\n",
            "==> Epoch 5 Summary: Total Loss = 334.1113, Accuracy = 88.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total parameters:\", total_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnYLswIN5PIB",
        "outputId": "799fc7ba-f43b-4067-e4e1-ab3d6698e8d0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 2986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_data:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = 100.0 * correct / total\n",
        "print(f\"\\n==> Val Accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbd6PQmG52QB",
        "outputId": "0e0ae6f3-c8e6-4fd8-dbe1-80b64ffd7afd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> Val Accuracy: 89.39%\n"
          ]
        }
      ]
    }
  ]
}